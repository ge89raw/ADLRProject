{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPARATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "import ddpm\n",
    "import datasets\n",
    "\n",
    "import os\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version Installed: 2.0.1+cu117\n",
      "Torchvision version Installed: 0.15.2+cu117\n",
      "\n",
      "you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it might cause dependency and compatibility issues.\n",
      "you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it might cause dependency and compatibility issues.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"1.11\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.12\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET & DATALOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA NORMALIZATION FUNCTION PRIOR TO DATASET GENERATION\n",
    "\n",
    "# Import dataset class\n",
    "from grasp_object_dataset import graspDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to obtain mean, std, max, and min of given dataset\n",
    "def get_mean_std(main_dir, object_dir, dataset):\n",
    "\n",
    "    # Allocate variables\n",
    "    full_joints = []\n",
    "\n",
    "    # Load all samples - only joint values!\n",
    "    for sample in tqdm(dataset):\n",
    "        joints = sample[0]\n",
    "        full_joints.append(joints)\n",
    "\n",
    "    mean = np.mean(full_joints, axis = 0)\n",
    "    std = np.std(full_joints, axis = 0)\n",
    "    max = np.max(full_joints, axis = 0)\n",
    "    min = np.min(full_joints, axis = 0)\n",
    "    \n",
    "\n",
    "    return mean, std, max, min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37de26e47b404d68b5cad15747b7d979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT NORMALIZED:  [array([ 0.0392823 ,  0.31361202,  0.70816582,  0.29692368,  0.07207266,\n",
      "        0.31826818,  0.49531689,  0.22077443,  0.1136933 ,  0.30901805,\n",
      "        0.71981804,  0.18223994,  0.24598885, -0.00452761,  0.15958449,\n",
      "        0.59792489,  0.23905943,  0.38096319,  0.97673997, -0.0487463 ,\n",
      "       -0.39349605, -0.07124564, -0.17433854,  0.36593643, -2.36187123,\n",
      "       -0.05151258, -0.05443905, -0.0173604 ]), array([0.02517107, 0.09351697, 0.02072358, 0.28532102, 0.00295238,\n",
      "       0.04999459, 0.28136656, 0.22077773, 0.01399565, 0.04496688,\n",
      "       0.36168404, 0.18209226, 0.17415622, 0.04522972, 0.06109539,\n",
      "       0.2885344 , 0.23899754, 0.07810427, 0.10572949, 0.05585855,\n",
      "       0.09310748, 0.07385562, 1.37517608, 0.13581058, 0.7259894 ,\n",
      "       0.06679289, 0.10399817, 0.01794473]), array([ 6.44533709e-02,  4.07128990e-01,  7.28889406e-01,  5.82244694e-01,\n",
      "        7.50250369e-02,  3.68262768e-01,  7.76683450e-01,  4.41552162e-01,\n",
      "        1.27688959e-01,  3.53984922e-01,  1.08150208e+00,  3.64332199e-01,\n",
      "        4.20145065e-01,  4.07021046e-02,  2.20679879e-01,  8.86459291e-01,\n",
      "        4.78056967e-01,  4.59067464e-01,  1.08246946e+00,  7.11224787e-03,\n",
      "       -3.00388575e-01,  2.60998355e-03,  1.20083754e+00,  5.01747014e-01,\n",
      "       -1.63588184e+00,  1.52803073e-02,  4.95591238e-02,  5.84329362e-04]), array([ 1.41112227e-02,  2.20095053e-01,  6.87442243e-01,  1.16026569e-02,\n",
      "        6.91202804e-02,  2.68273592e-01,  2.13950321e-01, -3.29715704e-06,\n",
      "        9.96976495e-02,  2.64051169e-01,  3.58134001e-01,  1.47672370e-04,\n",
      "        7.18326345e-02, -4.97573279e-02,  9.84890983e-02,  3.09390485e-01,\n",
      "        6.18838676e-05,  3.02858919e-01,  8.71010482e-01, -1.04604848e-01,\n",
      "       -4.86603528e-01, -1.45101264e-01, -1.54951462e+00,  2.30125851e-01,\n",
      "       -3.08786063e+00, -1.18305467e-01, -1.58437222e-01, -3.53051350e-02])]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432b2d1387274a8b83307356869a6027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALIZED:  [array([-1.98287501e-11, -5.39881739e-12, -2.41051935e-11, -1.77459825e-12,\n",
      "       -1.69381739e-10, -1.00043849e-11, -1.80716930e-12, -2.27301178e-12,\n",
      "       -3.57013015e-11, -1.11378962e-11, -1.36714190e-12, -2.73126854e-12,\n",
      "       -2.90856406e-12, -1.10867271e-11, -8.18539547e-12, -1.76441617e-12,\n",
      "       -2.06005962e-12, -6.37760422e-12, -4.76114792e-12, -8.91486707e-12,\n",
      "       -5.40238454e-12, -6.80687234e-12, -3.99950295e-13, -3.65162123e-12,\n",
      "       -6.82347512e-13, -7.50054596e-12, -4.78594236e-12, -2.79094934e-11]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "       -1., -1.])]\n"
     ]
    }
   ],
   "source": [
    "# DATASET AND DATALOADER DEFINITION\n",
    "\n",
    "# Import dataset class\n",
    "from grasp_object_dataset import graspDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Directories of dataset grasps + objects: set to a small version of it to overfit!! Full version found in dataset_XX_full\n",
    "main_dir = './dataset_grasps/'\n",
    "object_dir = './dataset_objects/'\n",
    "\n",
    "# Generate dataset with all dataset samples\n",
    "main_dataset = graspDataset(main_dir, object_dir, mode = 'train', split = {'train': 1, 'val': 0, 'test': 0}, normalization=None, transform_joint = None, transform_object = None)\n",
    "\n",
    "# Calculate mean, std, max, min of full dataset\n",
    "mean_std_max_min = list(get_mean_std(main_dir, object_dir, main_dataset))\n",
    "# Print not norm data\n",
    "print('NOT NORMALIZED: ', mean_std_max_min)\n",
    "\n",
    "# Datasets definition\n",
    "train_dataset = graspDataset(main_dir, object_dir, mode = 'train', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "val_dataset = graspDataset(main_dir, object_dir, mode = 'val', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "test_dataset = graspDataset(main_dir, object_dir, mode = 'test', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "\n",
    "# Comparison for normalized dataset\n",
    "mean_std_max_min_2 = list(get_mean_std(main_dir, object_dir, train_dataset))\n",
    "print('NORMALIZED: ', mean_std_max_min_2)\n",
    "\n",
    "# Dataloader definition\n",
    "train_dataloader = DataLoader(train_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)\n",
    "val_dataloader = DataLoader(val_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[0. 1. 0.]\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# DATASET INDICES\n",
    "\n",
    "# train_dataset[sample][index]\n",
    "# index = 0 --> joint angles\n",
    "# index = 1 --> label (grasp type) - one hot vector\n",
    "# index = 2 --> matrix distances\n",
    "# index = 3 --> file name\n",
    "\n",
    "print(train_dataset[5000][1])\n",
    "print(train_dataset[1000][1])\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIFFUSION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS FOR TUNING\n",
    "\n",
    "# model\n",
    "hidden_size = 128\n",
    "hidden_layers = 3\n",
    "emb_size= 128\n",
    "time_emb= \"sinusoidal\"\n",
    "input_emb= \"sinusoidal\"\n",
    "\n",
    "# Noise scheduler\n",
    "num_timesteps = 50\n",
    "beta_schedule= 'linear'\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 1e-6\n",
    "\n",
    "#training\n",
    "num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ddpm.MLP(\n",
    "        hidden_size= hidden_size,\n",
    "        hidden_layers=hidden_layers,\n",
    "        emb_size= emb_size,\n",
    "        time_emb= time_emb,\n",
    "        input_emb= input_emb\n",
    "        )\n",
    "\n",
    "noise_scheduler = ddpm.NoiseScheduler(\n",
    "        num_timesteps=num_timesteps,\n",
    "        beta_schedule=beta_schedule)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr= learning_rate,\n",
    "    )\n",
    "\n",
    "avg_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d1c5a6e8d940fda4ceda0077359e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b965fc675ee4153987d11400d99ac1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93af532dd5644c37a25d4b390f4a84f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f6dd3c77914a6292bf9f1b2cd7b571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040a526654ba4012ad3cf11dcf26194c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd22f6afe5a486bb41b84938ac106f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d7117b6cb34ef99c08da3af71415ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3da5a78cd954b829fb567d5993e23a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852c16ec15ea4987b041c3ad0a8d4ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23bf859f476459f8780eaba427d612a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1dc50e50bd46399ccd3de9e55f36f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3f3cbcbed34ce39480a69ee41fa1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m noise_pred \u001b[39m=\u001b[39m model(noisy, timesteps, label_one_hot, mat_distances)\n\u001b[1;32m     22\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[0;32m---> 23\u001b[0m loss\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m     25\u001b[0m nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "frames = []\n",
    "losses = []\n",
    "print(\"Training model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(total=len(train_dataloader))\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Variables\n",
    "        joint_angles_batch = batch[0] \n",
    "        label_one_hot = batch[1]\n",
    "        mat_distances = batch[2] \n",
    "\n",
    "        # Noise and timesteps\n",
    "        noise = torch.randn(joint_angles_batch.shape)\n",
    "        timesteps = torch.randint(0, noise_scheduler.num_timesteps, (joint_angles_batch.shape[0],)).long()\n",
    "\n",
    "        noisy = noise_scheduler.add_noise(joint_angles_batch, noise, timesteps)\n",
    "        noisy = noisy.double()\n",
    "        noise_pred = model(noisy, timesteps, label_one_hot, mat_distances)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        loss.backward(loss)\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
    "        losses.append(loss.detach().item())\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        global_step += 1\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    avg_loss.append(np.mean(losses))\n",
    "    losses = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    if epoch % config.save_images_step == 0 or epoch == config.num_epochs - 1:\n",
    "        # generate data with the model to later visualize the learning process\n",
    "        model.eval()\n",
    "        sample = torch.randn(config.eval_batch_size, 2)\n",
    "        timesteps = list(range(len(noise_scheduler)))[::-1]\n",
    "        for i, t in enumerate(tqdm(timesteps)):\n",
    "            t = torch.from_numpy(np.repeat(t, config.eval_batch_size)).long()\n",
    "            with torch.no_grad():\n",
    "                residual = model(sample, t)\n",
    "            sample = noise_scheduler.step(residual, t[0], sample)\n",
    "        frames.append(sample.numpy())\n",
    "\n",
    "print(\"Saving model...\")\n",
    "outdir = f\"exps/{config.experiment_name}\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"{outdir}/model.pth\")\n",
    "\n",
    "print(\"Saving images...\")\n",
    "imgdir = f\"{outdir}/images\"\n",
    "os.makedirs(imgdir, exist_ok=True)\n",
    "frames = np.stack(frames)\n",
    "xmin, xmax = -6, 6\n",
    "ymin, ymax = -6, 6\n",
    "for i, frame in enumerate(frames):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(frame[:, 0], frame[:, 1])\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.savefig(f\"{imgdir}/{i:04}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "print(\"Saving loss as numpy array...\")\n",
    "np.save(f\"{outdir}/loss.npy\", np.array(losses))\n",
    "print(\"Saving frames...\")\n",
    "np.save(f\"{outdir}/frames.npy\", frames)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the 1D array as a line plot\n",
    "plt.plot(avg_loss)\n",
    "\n",
    "# Add labels and title (optional)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Line Plot of 1D Array')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model...\")\n",
    "experiment_name = 'full_normalization'\n",
    "outdir = f\"exps/{experiment_name}\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"{outdir}/model_pruebas.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL INFERENCE --> EVALUATION OF RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tUnexpected key(s) in state_dict: \"conv_layers.0.weight\", \"conv_layers.0.bias\", \"conv_layers.3.weight\", \"conv_layers.3.bias\", \"conv_layers.6.weight\", \"conv_layers.6.bias\", \"conv_layers.10.weight\", \"conv_layers.10.bias\". \n\tsize mismatch for joint_mlp.0.weight: copying a param with shape torch.Size([128, 4227]) from checkpoint, the shape in current model is torch.Size([128, 3715]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load a model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m ddpm\u001b[39m.\u001b[39mMLP(\n\u001b[1;32m      4\u001b[0m         hidden_size\u001b[39m=\u001b[39m hidden_size,\n\u001b[1;32m      5\u001b[0m         hidden_layers\u001b[39m=\u001b[39mhidden_layers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         input_emb\u001b[39m=\u001b[39m input_emb\n\u001b[1;32m      9\u001b[0m         )\n\u001b[0;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./model_norm.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tUnexpected key(s) in state_dict: \"conv_layers.0.weight\", \"conv_layers.0.bias\", \"conv_layers.3.weight\", \"conv_layers.3.bias\", \"conv_layers.6.weight\", \"conv_layers.6.bias\", \"conv_layers.10.weight\", \"conv_layers.10.bias\". \n\tsize mismatch for joint_mlp.0.weight: copying a param with shape torch.Size([128, 4227]) from checkpoint, the shape in current model is torch.Size([128, 3715])."
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Load a model\n",
    "\n",
    "model = ddpm.MLP(\n",
    "        hidden_size= hidden_size,\n",
    "        hidden_layers=hidden_layers,\n",
    "        emb_size= emb_size,\n",
    "        time_emb= time_emb,\n",
    "        input_emb= input_emb\n",
    "        )\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('./model_norm.pth'))\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for grasping validation\n",
    "main_dir = './dataset_grasps/'\n",
    "object_dir = './dataset_objects/'\n",
    "\n",
    "# Grasp code for which we have overfitting\n",
    "grasp_code = 'core-bottle-1ae823260851f7d9ea600d1a6d9f6e07'\n",
    "\n",
    "# Load matrix distance for given object\n",
    "matriz_distancias = np.load(os.path.join(object_dir+grasp_code+\".npy\"), allow_pickle=True)*0.11\n",
    "matriz_distancias = torch.from_numpy(matriz_distancias)\n",
    "matriz_distancias = matriz_distancias.reshape(1, 50, 50, 50)\n",
    "\n",
    "# Define matrix for given object\n",
    "label = torch.tensor([1, 0, 0])\n",
    "label = label.reshape(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2f5eb1dd1464fad46c2a7ca48ee62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model inference\n",
    "model.eval()\n",
    "\n",
    "eval_batch_size = 1\n",
    "num_timesteps = 50\n",
    "plot_step = 5\n",
    "\n",
    "noise_scheduler = ddpm.NoiseScheduler(num_timesteps=num_timesteps)\n",
    "sample = torch.randn(eval_batch_size, 28)\n",
    "timesteps = list(range(num_timesteps))[::-1]\n",
    "\n",
    "samples = []\n",
    "steps = []\n",
    "\n",
    "for i, t in enumerate(tqdm(timesteps)):\n",
    "    t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t, label, matriz_distancias)\n",
    "        \n",
    "    sample = noise_scheduler.step(residual, t[0], sample)\n",
    "    if (i + 1) % plot_step == 0:\n",
    "        samples.append(sample.numpy())\n",
    "        steps.append(i + 1)\n",
    "\n",
    "# Generated test grasp is saved in samples[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "reference = train_dataset[5000][0]\n",
    "print(train_dataset[5000][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06445337  0.22009505  0.72888941  0.58224469  0.07502504  0.26827359\n",
      "  0.77668345  0.44155216  0.12768896  0.35398492  1.08150208  0.3643322\n",
      "  0.07183263  0.0407021   0.0984891   0.88645929  0.47805697  0.30285892\n",
      "  0.87101048 -0.10460485 -0.30038857  0.00260998 -1.54951462  0.23012585\n",
      " -1.63588184 -0.11830547  0.04955912 -0.03530513]\n",
      "[ 0.05144056  0.27522924  0.7174202   0.43487125  0.07382652  0.28684472\n",
      "  0.6185025   0.30828432  0.12004765  0.33098035  0.88676762  0.27823958\n",
      "  0.17041385  0.02056521  0.13564989  0.69987275  0.32345628  0.34496171\n",
      "  0.93176276 -0.07278473 -0.35866475 -0.03858891 -0.89117785  0.30086937\n",
      " -2.02830268 -0.07895565 -0.00617681 -0.02633998]\n",
      "[ 0.01301281 -0.05513419  0.01146921  0.14737344  0.00119852 -0.01857113\n",
      "  0.15818095  0.13326784  0.00764131  0.02300457  0.19473446  0.08609262\n",
      " -0.09858122  0.0201369  -0.0371608   0.18658654  0.15460069 -0.0421028\n",
      " -0.06075228 -0.03182012  0.05827617  0.04119889 -0.65833676 -0.07074352\n",
      "  0.39242084 -0.03934982  0.05573593 -0.00896515]\n"
     ]
    }
   ],
   "source": [
    "# Print of joint angles for predicted grasp\n",
    "reference = (reference + 1)/2\n",
    "reference = reference * (mean_std_max_min[2]- mean_std_max_min[3]) + mean_std_max_min[3]\n",
    "print(reference)\n",
    "\n",
    "\n",
    "# Set sample to predicted test sample\n",
    "sample = samples[-1][0]\n",
    "\n",
    "# Return normalized values to the initial values\n",
    "sample = (sample + 1)/2\n",
    "sample = sample * (mean_std_max_min[2]- mean_std_max_min[3]) + mean_std_max_min[3]\n",
    "\n",
    "print(sample)\n",
    "\n",
    "\n",
    "print(reference - sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALIZATION OF RESULT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgual/.local/lib/python3.9/site-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from utils.hand_model_lite import HandModelMJCFLite\n",
    "import numpy as np\n",
    "import transforms3d\n",
    "import torch\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_path = './test_files/meshdata/'\n",
    "data_path = './test_files/dexgraspnet/'\n",
    "\n",
    "\n",
    "use_visual_mesh = False\n",
    "\n",
    "hand_file = \"mjcf/shadow_hand_vis.xml\" if use_visual_mesh else \"mjcf/shadow_hand_wrist_free.xml\"\n",
    "\n",
    "joint_names = [\n",
    "    'robot0:FFJ3', 'robot0:FFJ2', 'robot0:FFJ1', 'robot0:FFJ0',\n",
    "    'robot0:MFJ3', 'robot0:MFJ2', 'robot0:MFJ1', 'robot0:MFJ0',\n",
    "    'robot0:RFJ3', 'robot0:RFJ2', 'robot0:RFJ1', 'robot0:RFJ0',\n",
    "    'robot0:LFJ4', 'robot0:LFJ3', 'robot0:LFJ2', 'robot0:LFJ1', 'robot0:LFJ0',\n",
    "    'robot0:THJ4', 'robot0:THJ3', 'robot0:THJ2', 'robot0:THJ1', 'robot0:THJ0'\n",
    "]\n",
    "translation_names = ['WRJTx', 'WRJTy', 'WRJTz']\n",
    "rot_names = ['WRJRx', 'WRJRy', 'WRJRz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid geometry type box.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load hand file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hand_model \u001b[39m=\u001b[39m HandModelMJCFLite(\n\u001b[1;32m      3\u001b[0m     hand_file,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmjcf/meshes\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/ADLRProject/utils/hand_model_lite.py:30\u001b[0m, in \u001b[0;36mHandModelMJCFLite.__init__\u001b[0;34m(self, mjcf_path, mesh_path, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mCreate a Lite Hand Model for a MJCF robot\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m    device for torch tensors\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[0;32m---> 30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain \u001b[39m=\u001b[39m pk\u001b[39m.\u001b[39;49mbuild_chain_from_mjcf(\n\u001b[1;32m     31\u001b[0m     \u001b[39mopen\u001b[39;49m(mjcf_path)\u001b[39m.\u001b[39;49mread())\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dofs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mget_joint_parameter_names())\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmesh \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_kinematics/mjcf.py:67\u001b[0m, in \u001b[0;36mbuild_chain_from_mjcf\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     62\u001b[0m root_body \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mworldbody\u001b[39m.\u001b[39mbody[\u001b[39m0\u001b[39m]\n\u001b[1;32m     63\u001b[0m root_frame \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mFrame(root_body\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_frame\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m                          link\u001b[39m=\u001b[39mframe\u001b[39m.\u001b[39mLink(root_body\u001b[39m.\u001b[39mname,\n\u001b[1;32m     65\u001b[0m                                          offset\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mTransform3d(rot\u001b[39m=\u001b[39mroot_body\u001b[39m.\u001b[39mquat, pos\u001b[39m=\u001b[39mroot_body\u001b[39m.\u001b[39mpos)),\n\u001b[1;32m     66\u001b[0m                          joint\u001b[39m=\u001b[39mframe\u001b[39m.\u001b[39mJoint())\n\u001b[0;32m---> 67\u001b[0m _build_chain_recurse(root_frame, root_body)\n\u001b[1;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m chain\u001b[39m.\u001b[39mChain(root_frame)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_kinematics/mjcf.py:26\u001b[0m, in \u001b[0;36m_build_chain_recurse\u001b[0;34m(parent_frame, parent_body)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_chain_recurse\u001b[39m(parent_frame, parent_body):\n\u001b[0;32m---> 26\u001b[0m     parent_frame\u001b[39m.\u001b[39mlink\u001b[39m.\u001b[39mvisuals \u001b[39m=\u001b[39m geoms_to_visuals(parent_body\u001b[39m.\u001b[39;49mgeom)\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m parent_body\u001b[39m.\u001b[39mbody:\n\u001b[1;32m     28\u001b[0m         n_joints \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(b\u001b[39m.\u001b[39mjoint)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_kinematics/mjcf.py:20\u001b[0m, in \u001b[0;36mgeoms_to_visuals\u001b[0;34m(geom)\u001b[0m\n\u001b[1;32m     18\u001b[0m         param \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid geometry type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m g\u001b[39m.\u001b[39mtype)\n\u001b[1;32m     21\u001b[0m     visuals\u001b[39m.\u001b[39mappend(frame\u001b[39m.\u001b[39mVisual(offset\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mTransform3d(rot\u001b[39m=\u001b[39mg\u001b[39m.\u001b[39mquat, pos\u001b[39m=\u001b[39mg\u001b[39m.\u001b[39mpos), geom_type\u001b[39m=\u001b[39mg\u001b[39m.\u001b[39mtype, geom_param\u001b[39m=\u001b[39mparam))\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m visuals\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid geometry type box."
     ]
    }
   ],
   "source": [
    "# Load hand file\n",
    "hand_model = HandModelMJCFLite(\n",
    "    hand_file,\n",
    "    \"mjcf/meshes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grasp original code and object\n",
    "grasp_code = 'core-bottle-1ae823260851f7d9ea600d1a6d9f6e07'\n",
    "grasp_data = np.load(\n",
    "    os.path.join(data_path, grasp_code+\".npy\"), allow_pickle=True)\n",
    "object_mesh_origin = trimesh.load(os.path.join(\n",
    "    mesh_path, grasp_code, \"coacd/decomposed.obj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'robot0:FFJ3': -0.24548496305942535, 'robot0:FFJ2': 0.6087559461593628, 'robot0:FFJ1': 0.7188290357589722, 'robot0:FFJ0': 0.2019304633140564, 'robot0:MFJ3': -0.17577102780342102, 'robot0:MFJ2': 0.38283923268318176, 'robot0:MFJ1': 1.1127177476882935, 'robot0:MFJ0': 0.403972327709198, 'robot0:RFJ3': -0.07210764288902283, 'robot0:RFJ2': 0.1400628387928009, 'robot0:RFJ1': 0.9195994138717651, 'robot0:RFJ0': 0.41342633962631226, 'robot0:LFJ4': 0.18373392522335052, 'robot0:LFJ3': 0.025994563475251198, 'robot0:LFJ2': 0.13054056465625763, 'robot0:LFJ1': 0.9286351203918457, 'robot0:LFJ0': 0.47552821040153503, 'robot0:THJ4': -0.0618005096912384, 'robot0:THJ3': 1.1335370540618896, 'robot0:THJ2': 0.041698239743709564, 'robot0:THJ1': -0.13501165807247162, 'robot0:THJ0': -2.997061756104813e-06, 'WRJRx': 3.0913850314695135, 'WRJRy': 0.2305903394170629, 'WRJRz': -2.3657796059005416, 'WRJTx': -0.043085746467113495, 'WRJTy': 0.09048712253570557, 'WRJTz': 0.1175876185297966}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hand_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m rot \u001b[39m=\u001b[39m rot[:, :\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mravel()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     24\u001b[0m hand_pose \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([qpos[name] \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m translation_names] \u001b[39m+\u001b[39m rot \u001b[39m+\u001b[39m [qpos[name]\n\u001b[1;32m     25\u001b[0m                          \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m joint_names], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m hand_model\u001b[39m.\u001b[39mset_parameters(hand_pose)\n\u001b[1;32m     27\u001b[0m hand_mesh \u001b[39m=\u001b[39m hand_model\u001b[39m.\u001b[39mget_trimesh_data(\u001b[39m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m object_mesh \u001b[39m=\u001b[39m object_mesh_origin\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mapply_scale(\u001b[39m0.11\u001b[39m)\u001b[39m#grasp_data[index][\"scale\"])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hand_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Select first grasph - could be any\n",
    "index = 0\n",
    "\n",
    "# Set sample to predicted test sample\n",
    "sample = samples[-1][0]\n",
    "\n",
    "# Return normalized values to the initial values\n",
    "sample = (sample + 1)/2\n",
    "sample = sample * (mean_std_max_min[2]- mean_std_max_min[3]) + mean_std_max_min[3]\n",
    "\n",
    "\n",
    "# Substitute values in grasp for the predicted ones\n",
    "qpos = grasp_data[index]['qpos']\n",
    "i=0\n",
    "for key in qpos:\n",
    "    qpos[key] = sample[i]\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "rot = np.array(transforms3d.euler.euler2mat(\n",
    "    *[qpos[name] for name in rot_names]))\n",
    "rot = rot[:, :2].T.ravel().tolist()\n",
    "hand_pose = torch.tensor([qpos[name] for name in translation_names] + rot + [qpos[name]\n",
    "                         for name in joint_names], dtype=torch.float, device=\"cpu\").unsqueeze(0)\n",
    "hand_model.set_parameters(hand_pose)\n",
    "hand_mesh = hand_model.get_trimesh_data(0)\n",
    "object_mesh = object_mesh_origin.copy().apply_scale(0.11)#grasp_data[index][\"scale\"])\n",
    "\n",
    "(hand_mesh+object_mesh).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
