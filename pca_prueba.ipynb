{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "import ddpm\n",
    "import datasets\n",
    "\n",
    "import os\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version Installed: 2.0.1+cu117\n",
      "Torchvision version Installed: 0.15.2+cu117\n",
      "\n",
      "you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it might cause dependency and compatibility issues.\n",
      "you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it might cause dependency and compatibility issues.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"1.11\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.12\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA NORMALIZATION FUNCTION PRIOR TO DATASET GENERATION\n",
    "\n",
    "# Import dataset class\n",
    "from grasp_object_dataset import graspDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to obtain mean, std, max, and min of given dataset\n",
    "def get_mean_std(main_dir, object_dir, dataset):\n",
    "\n",
    "    # Allocate variables\n",
    "    full_joints = []\n",
    "\n",
    "    # Load all samples - only joint values!\n",
    "    for sample in tqdm(dataset):\n",
    "        joints = sample[0]\n",
    "        full_joints.append(joints)\n",
    "\n",
    "    mean = np.mean(full_joints, axis = 0)\n",
    "    std = np.std(full_joints, axis = 0)\n",
    "    max = np.max(full_joints, axis = 0)\n",
    "    min = np.min(full_joints, axis = 0)\n",
    "    \n",
    "\n",
    "    return mean, std, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b47e2bf324271b90db07018b0f2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT NORMALIZED:  [array([ 3.98561844e-02,  2.57192661e-01,  5.95373810e-01,  1.67236000e-01,\n",
      "        2.65023496e-02,  2.65105132e-01,  6.80795671e-01,  1.57267439e-01,\n",
      "        1.17773209e-02,  3.03083575e-01,  6.61583456e-01,  1.70557048e-01,\n",
      "        2.61156612e-01, -1.07516990e-01,  2.03640379e-01,  5.48817102e-01,\n",
      "        2.04976352e-01,  2.73408066e-01,  1.04242190e+00, -1.19935514e-02,\n",
      "       -2.36260475e-01, -6.06011368e-02, -6.05525100e-02,  8.50713967e-03,\n",
      "       -2.46173353e-02,  6.38794029e-05, -3.58334739e-03, -7.04945023e-04]), array([0.08841094, 0.12425186, 0.13485115, 0.17028817, 0.08242855,\n",
      "       0.10374933, 0.19098119, 0.17153302, 0.09209367, 0.11868084,\n",
      "       0.17730865, 0.17665884, 0.10540849, 0.08868023, 0.09023743,\n",
      "       0.23112383, 0.19124254, 0.22412766, 0.11790531, 0.10479109,\n",
      "       0.20813474, 0.08463916, 1.78267916, 0.65887648, 1.78051084,\n",
      "       0.09024645, 0.09977398, 0.08307887]), array([0.44093332, 0.72629118, 1.05269575, 0.85050714, 0.34213725,\n",
      "       0.64492512, 1.19663477, 0.82167763, 0.39223263, 0.69821125,\n",
      "       1.25505531, 0.88972026, 0.6487124 , 0.29735902, 0.5676797 ,\n",
      "       1.35183764, 0.90264493, 0.85987097, 1.3856436 , 0.28555614,\n",
      "       0.33479431, 0.1156234 , 3.14151842, 1.56275215, 3.14117853,\n",
      "       0.24402052, 0.24384201, 0.24099013]), array([-0.27196452, -0.1602633 ,  0.1688364 , -0.02377819, -0.28478035,\n",
      "       -0.05147971,  0.03755141, -0.01531817, -0.34954494, -0.08357178,\n",
      "        0.09193815, -0.07518398, -0.19508421, -0.42915052, -0.08831821,\n",
      "       -0.02411517, -0.03082316, -0.2938734 ,  0.44319621, -0.29617727,\n",
      "       -0.78017813, -0.50623453, -3.14148423, -1.56842095, -3.14069212,\n",
      "       -0.24556136, -0.24849886, -0.24206661])]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67f951f0dc24b4d8559dbb31c284fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALIZED:  [array([-0.12520227, -0.05825086, -0.03482967, -0.56303924, -0.00694221,\n",
      "       -0.09080227,  0.1099189 , -0.58760699, -0.0257935 , -0.01083718,\n",
      "       -0.02048508, -0.49064162,  0.0814    , -0.11457864, -0.10987953,\n",
      "       -0.16722104, -0.49478828, -0.01662538,  0.27163743, -0.02297611,\n",
      "       -0.02433884,  0.43323216, -0.01928046,  0.00724428, -0.00791501,\n",
      "        0.00340821, -0.00509778, -0.00069022]), array([0.24803257, 0.28030283, 0.30514164, 0.38954828, 0.26296456,\n",
      "       0.29795695, 0.32953832, 0.40987787, 0.24830535, 0.30361581,\n",
      "       0.30488528, 0.36616864, 0.24984337, 0.2441268 , 0.27511499,\n",
      "       0.33594732, 0.40974628, 0.38852221, 0.25021091, 0.36027187,\n",
      "       0.37334508, 0.27221381, 0.5674609 , 0.42084961, 0.56687281,\n",
      "       0.36866746, 0.40530449, 0.34397149]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "       -1., -1.])]\n"
     ]
    }
   ],
   "source": [
    "# DATASET AND DATALOADER DEFINITION\n",
    "\n",
    "# Import dataset class\n",
    "from grasp_object_dataset import graspDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Directories of dataset grasps + objects: set to a small version of it to overfit!! Full version found in dataset_XX_full\n",
    "main_dir = './dataset_grasps_full/'\n",
    "object_dir = './dataset_objects_full/'\n",
    "\n",
    "# Generate dataset with all dataset samples\n",
    "main_dataset = graspDataset(main_dir, object_dir, mode = 'train', split = {'train': 1, 'val': 0, 'test': 0}, normalization=None, transform_joint = None, transform_object = None)\n",
    "\n",
    "# Calculate mean, std, max, min of full dataset\n",
    "mean_std_max_min = list(get_mean_std(main_dir, object_dir, main_dataset))\n",
    "# Print not norm data\n",
    "print('NOT NORMALIZED: ', mean_std_max_min)\n",
    "\n",
    "# Datasets definition\n",
    "train_dataset = graspDataset(main_dir, object_dir, mode = 'train', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "#val_dataset = graspDataset(main_dir, object_dir, mode = 'val', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "#test_dataset = graspDataset(main_dir, object_dir, mode = 'test', split = {'train': 1, 'val': 0, 'test': 0}, normalization=mean_std_max_min)#, transform_joint = None, transform_object = None)\n",
    "\n",
    "# Comparison for normalized dataset\n",
    "mean_std_max_min_2 = list(get_mean_std(main_dir, object_dir, train_dataset))\n",
    "print('NORMALIZED: ', mean_std_max_min_2)\n",
    "\n",
    "# Dataloader definition\n",
    "train_dataloader = DataLoader(train_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)\n",
    "#val_dataloader = DataLoader(val_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)\n",
    "#test_dataloader = DataLoader(test_dataset , batch_size=64, shuffle=True, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      5\u001b[0m \u001b[39m# Path to the 'dataset' folder\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dataset_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_components = 10\n",
    "pca = PCA(n_components=num_components)\n",
    "\n",
    "# Iterate through batches\n",
    "for batch in train_dataloader:\n",
    "    joint_angles_batch = batch[0]\n",
    "    # Fit the PCA model to the batch and transform it to reduced dimensionality\n",
    "    reduced_data = pca.fit_transform(joint_angles_batch)\n",
    "    # Inverse transform to reconstruct the batch\n",
    "    reconstructed_data = pca.inverse_transform(reduced_data)\n",
    "\n",
    "    # Check the shape of the reconstructed batch\n",
    "    print(\"Shape of reconstructed batch:\", reconstructed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
